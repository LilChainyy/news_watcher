"""
PRACTICAL TUTORIAL - Step-by-Step Usage Guide

This script walks you through using the correlation engine
with detailed examples and explanations.

Run this AFTER you've collected some historical data.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Your modules
from correlation_engine import EventImpactAnalyzer
from statistical_analysis import (
    CorrelationValidator, 
    RiskMetricsCalculator,
    EventStudyAnalysis
)
from data_loader import DataPipeline


def tutorial_step_1_load_data():
    """
    STEP 1: Load and Validate Your Data
    
    This is the foundation. Bad data = bad results.
    """
    print("="*70)
    print("STEP 1: LOADING DATA")
    print("="*70 + "\n")
    
    # Initialize data pipeline
    pipeline = DataPipeline(data_dir="./data")
    
    # Load data
    print("ğŸ“‚ Loading historical events and prices...")
    events_df, prices_df = pipeline.run_pipeline()
    
    # Quick inspection
    print("\nğŸ“Š Data Overview:")
    print(f"   Events: {len(events_df)} records")
    print(f"   Date range: {events_df['date'].min()} to {events_df['date'].max()}")
    print(f"   Tickers: {events_df['ticker'].nunique()} unique")
    print(f"   Event types: {list(events_df['event_type'].unique())}")
    
    print(f"\n   Prices: {len(prices_df)} records")
    print(f"   Tickers: {prices_df['ticker'].nunique()} unique")
    
    # Check for issues
    print("\nğŸ” Data Quality Check:")
    missing_events = events_df.isna().sum()
    if missing_events.any():
        print("   âš ï¸  Missing data in events:")
        print(missing_events[missing_events > 0])
    else:
        print("   âœ… No missing data in events")
    
    print("\nğŸ’¡ Key Point:")
    print("   You need at least 6 months of data and 20+ events per type")
    print("   for statistically significant results.")
    
    return events_df, prices_df


def tutorial_step_2_calculate_basic_impact(events_df, prices_df):
    """
    STEP 2: Calculate Impact of Events on Prices
    
    This is your event study methodology.
    """
    print("\n" + "="*70)
    print("STEP 2: CALCULATING EVENT IMPACTS")
    print("="*70 + "\n")
    
    # Initialize analyzer
    analyzer = EventImpactAnalyzer(lookback_days=180)
    analyzer.load_historical_data(events_df, prices_df)
    
    # Pick a specific event to analyze
    sample_event = events_df.iloc[0]
    
    print(f"ğŸ“Œ Analyzing Sample Event:")
    print(f"   Date: {sample_event['date']}")
    print(f"   Ticker: {sample_event['ticker']}")
    print(f"   Type: {sample_event['event_type']}")
    
    # Calculate impact
    impact = analyzer.calculate_price_impact(
        sample_event['date'],
        sample_event['ticker'],
        window_hours=24
    )
    
    print(f"\nğŸ“ˆ Price Impact:")
    print(f"   1-hour return: {impact['return_1h']:+.2%}")
    print(f"   4-hour return: {impact['return_4h']:+.2%}")
    print(f"   24-hour return: {impact['return_24h']:+.2%}")
    print(f"   Volume change: {impact['volume_change']:+.1%}")
    
    print("\nğŸ’¡ Key Point:")
    print("   This shows how the stock moved AFTER the event.")
    print("   We'll compare this to normal market movements to find abnormal returns.")
    
    return analyzer


def tutorial_step_3_test_statistical_significance(analyzer, events_df):
    """
    STEP 3: Test if Correlations are Real or Just Noise
    
    This is critical - prevents you from trading on random patterns.
    """
    print("\n" + "="*70)
    print("STEP 3: STATISTICAL SIGNIFICANCE TESTING")
    print("="*70 + "\n")
    
    validator = CorrelationValidator(significance_level=0.05)
    
    # Get returns during events vs baseline
    ticker = events_df['ticker'].iloc[0]
    event_type = events_df['event_type'].iloc[0]
    
    # Collect returns during these events
    event_returns = []
    baseline_returns = []
    
    for idx, event in events_df[events_df['event_type'] == event_type].iterrows():
        impact = analyzer.calculate_price_impact(event['date'], event['ticker'])
        event_returns.append(impact['return_24h'])
    
    # TODO: Also collect baseline returns (non-event days)
    # For now, simulate
    baseline_returns = np.random.normal(0, 0.02, len(event_returns))
    event_returns = np.array(event_returns)
    
    # Test if event returns are significantly different
    result = validator.test_event_impact(event_returns, baseline_returns)
    
    print(f"ğŸ“Š Testing: {event_type} events")
    print(f"\n{result.interpretation}")
    print(f"\nStatistics:")
    print(f"   T-statistic: {result.statistic:.3f}")
    print(f"   P-value: {result.p_value:.4f}")
    print(f"   Significant? {'YES âœ…' if result.is_significant else 'NO âŒ'}")
    
    print("\nğŸ’¡ Key Point:")
    print("   P-value < 0.05 means less than 5% chance this is random.")
    print("   Only trade on correlations with p < 0.05!")
    
    return result


def tutorial_step_4_discover_hidden_correlations(analyzer):
    """
    STEP 4: Find Indirect Market Relationships
    
    This is THE MONEY PART - discovering hidden correlations.
    """
    print("\n" + "="*70)
    print("STEP 4: DISCOVERING HIDDEN CORRELATIONS")
    print("="*70 + "\n")
    
    print("ğŸ” Searching for indirect relationships...")
    print("   (This may take a minute...)\n")
    
    # Build correlation network
    correlation_matrix = analyzer.build_correlation_network()
    
    # Detect indirect correlations
    indirect_correlations = analyzer.detect_indirect_correlations(
        significance_level=0.05
    )
    
    if len(indirect_correlations) == 0:
        print("âŒ No significant indirect correlations found.")
        print("\n   Possible reasons:")
        print("   â€¢ Need more historical data")
        print("   â€¢ Events too diverse (try clustering)")
        print("   â€¢ Sample sizes too small")
        return
    
    print(f"âœ… Found {len(indirect_correlations)} significant relationships!\n")
    print("="*70)
    
    # Show top discoveries
    sorted_corr = sorted(
        indirect_correlations.items(),
        key=lambda x: abs(x[1]['avg_impact']),
        reverse=True
    )
    
    for i, (relationship, stats) in enumerate(sorted_corr[:5], 1):
        event_ticker, affected_ticker = relationship.split(" â†’ ")
        
        print(f"\n{i}. {relationship}")
        print(f"   {'â”€'*66}")
        print(f"   When {event_ticker} has news, {affected_ticker} moves {stats['avg_impact']:+.2%}")
        print(f"   ")
        print(f"   Confidence: {stats['confidence']:.1%} (p={stats['p_value']:.4f})")
        print(f"   Based on: {stats['sample_size']} historical events")
        
        # Trading interpretation
        direction = "DROPS" if stats['avg_impact'] < 0 else "RISES"
        print(f"   ")
        print(f"   ğŸ’¡ Trading Signal:")
        print(f"      Watch {affected_ticker} when {event_ticker} news breaks")
        print(f"      Expect {affected_ticker} to {direction} by ~{abs(stats['avg_impact']):.1%}")
    
    print("\n" + "="*70)
    print("\nğŸ’¡ Key Point:")
    print("   These are relationships the market hasn't priced in yet.")
    print("   You can potentially front-run the market with this info!")
    
    return indirect_correlations


def tutorial_step_5_calculate_risk_metrics(analyzer, ticker, event_type):
    """
    STEP 5: Calculate Risk Metrics
    
    Understand the risk/reward profile of trading on events.
    """
    print("\n" + "="*70)
    print("STEP 5: RISK ANALYSIS")
    print("="*70 + "\n")
    
    # Get risk metrics
    risk = analyzer.calculate_risk_metrics(ticker, event_type)
    
    print(f"ğŸ“Š Risk Profile: {ticker} during {event_type}")
    print("="*70)
    
    print(f"\nğŸ“ˆ Return Characteristics:")
    print(f"   Mean Return: {risk['mean_return']:+.2%}")
    print(f"   Volatility: {risk['volatility']:.2%}")
    print(f"   ")
    print(f"   Best Case: {risk['max_gain']:+.2%}")
    print(f"   Worst Case: {risk['max_drawdown']:+.2%}")
    
    print(f"\nğŸ“‰ Risk Metrics:")
    print(f"   VaR (95%): {risk['var_95']:.2%}")
    print(f"      â†’ 95% of time, loss won't exceed this")
    print(f"   ")
    print(f"   CVaR (95%): {risk['cvar_95']:.2%}")
    print(f"      â†’ Average loss in worst 5% of cases")
    
    print(f"\nâš–ï¸  Risk-Adjusted Performance:")
    print(f"   Sharpe Ratio: {risk['sharpe_ratio']:.2f}")
    
    interpretation = ""
    if risk['sharpe_ratio'] > 2:
        interpretation = "EXCELLENT - Very attractive risk/reward"
    elif risk['sharpe_ratio'] > 1:
        interpretation = "GOOD - Decent risk/reward"
    elif risk['sharpe_ratio'] > 0:
        interpretation = "OKAY - Positive but not great"
    else:
        interpretation = "POOR - Not worth the risk"
    
    print(f"      â†’ {interpretation}")
    
    print("\nğŸ’¡ Key Point:")
    print("   Sharpe > 1 is good, > 2 is excellent.")
    print("   VaR tells you maximum likely loss.")
    print("   CVaR tells you how bad the tail risk is.")
    
    return risk


def tutorial_step_6_predict_new_event(analyzer):
    """
    STEP 6: Use Your Model to Predict Impact of New Events
    
    This is the real-time application.
    """
    print("\n" + "="*70)
    print("STEP 6: PREDICTING NEW EVENT IMPACT")
    print("="*70 + "\n")
    
    # Simulate a breaking news event
    new_event = {
        'ticker': 'CRWV',
        'event_type': 'infrastructure_failure',
        'description': 'CoreWeave reports GPU cluster outage',
        'sentiment': -0.8,
        'entities': ['CoreWeave', 'GPU', 'cloud infrastructure']
    }
    
    print("ğŸš¨ BREAKING NEWS:")
    print(f"   {new_event['description']}")
    print(f"   Sentiment: {new_event['sentiment']:.1f} (very negative)")
    
    print("\nğŸ¤– Running Prediction Model...")
    
    # Get predictions
    predictions = analyzer.predict_impact(new_event)
    
    print("\n" + "="*70)
    print("PREDICTED PRICE IMPACTS")
    print("="*70)
    
    # Sort by magnitude
    sorted_predictions = sorted(
        predictions.items(),
        key=lambda x: abs(x[1]['predicted_return']),
        reverse=True
    )
    
    for ticker, pred in sorted_predictions:
        impact_type = "ğŸ¯ DIRECT" if pred['type'] == 'direct' else "ğŸ”— INDIRECT"
        
        print(f"\n{impact_type}: {ticker}")
        print(f"   Predicted Return: {pred['predicted_return']:+.2%}")
        print(f"   Confidence: {pred['confidence']:.1%}")
        
        if 'risk_range' in pred:
            print(f"   Risk Range: {pred['risk_range'][0]:.2%} to {pred['risk_range'][1]:.2%}")
        
        # Trading recommendation
        if abs(pred['predicted_return']) > 0.02 and pred['confidence'] > 0.7:
            print(f"   ")
            if pred['predicted_return'] > 0:
                print(f"   ğŸ’° Action: Consider LONG or sell puts")
            else:
                print(f"   âš ï¸  Action: AVOID or consider shorting")
        else:
            print(f"   ")
            print(f"   â¸ï¸  Action: WAIT - confidence too low or impact too small")
    
    print("\n" + "="*70)
    print("\nğŸ’¡ Key Point:")
    print("   Use these predictions to inform your trading decisions.")
    print("   But always combine with your own analysis!")
    print("   The model shows PROBABILITIES, not certainties.")
    
    return predictions


def tutorial_step_7_interpret_results():
    """
    STEP 7: How to Interpret and Use These Results
    
    Practical guide to applying your findings.
    """
    print("\n" + "="*70)
    print("STEP 7: INTERPRETING & APPLYING RESULTS")
    print("="*70 + "\n")
    
    print("ğŸ“š Guide to Interpretation:\n")
    
    print("1ï¸âƒ£  P-VALUES:")
    print("   â€¢ p < 0.01  â†’ Very strong evidence (99% confident)")
    print("   â€¢ p < 0.05  â†’ Strong evidence (95% confident) â† Use this threshold")
    print("   â€¢ p < 0.10  â†’ Weak evidence (90% confident)")
    print("   â€¢ p > 0.10  â†’ Not significant, ignore it")
    
    print("\n2ï¸âƒ£  CONFIDENCE SCORES:")
    print("   â€¢ > 80%  â†’ High confidence, can base trades on this")
    print("   â€¢ 70-80% â†’ Medium confidence, use with caution")
    print("   â€¢ < 70%  â†’ Low confidence, don't trade on this alone")
    
    print("\n3ï¸âƒ£  SAMPLE SIZE:")
    print("   â€¢ > 20  â†’ Reliable")
    print("   â€¢ 10-20 â†’ Okay but monitor")
    print("   â€¢ < 10  â†’ Too small, need more data")
    
    print("\n4ï¸âƒ£  EFFECT SIZE:")
    print("   â€¢ > 5%  â†’ Large effect, very tradable")
    print("   â€¢ 2-5%  â†’ Medium effect, good for options")
    print("   â€¢ < 2%  â†’ Small effect, might not be worth trading costs")
    
    print("\n" + "="*70)
    print("ğŸ¯ TRADING WORKFLOW:")
    print("="*70 + "\n")
    
    print("When News Breaks:")
    print("1. Check if it matches any of your event types")
    print("2. Run prediction model")
    print("3. Look at:")
    print("   â€¢ Predicted return (magnitude)")
    print("   â€¢ Confidence score (reliability)")
    print("   â€¢ Risk range (worst case)")
    print("4. Check indirect correlations")
    print("   â€¢ What other tickers might move?")
    print("5. Make trading decision:")
    print("   â€¢ High confidence + large effect = trade")
    print("   â€¢ Low confidence or small effect = pass")
    
    print("\n" + "="*70)
    print("âš ï¸  IMPORTANT WARNINGS:")
    print("="*70 + "\n")
    
    print("âŒ DON'T:")
    print("   â€¢ Trade on p-values > 0.05")
    print("   â€¢ Ignore sample size")
    print("   â€¢ Confuse correlation with causation")
    print("   â€¢ Over-optimize on historical data")
    print("   â€¢ Ignore your gut feel completely")
    
    print("\nâœ… DO:")
    print("   â€¢ Use multiple comparison corrections")
    print("   â€¢ Validate predictions out-of-sample")
    print("   â€¢ Update model regularly with new data")
    print("   â€¢ Combine with fundamental analysis")
    print("   â€¢ Start small and track accuracy")


def full_tutorial():
    """
    Run complete tutorial from start to finish
    """
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  MARKET INTELLIGENCE ENGINE - COMPLETE TUTORIAL                    â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("\nThis tutorial will walk you through the entire workflow.\n")
    
    input("Press Enter to start...")
    
    # Step 1: Load data
    events_df, prices_df = tutorial_step_1_load_data()
    input("\nâ–¶ Press Enter to continue to Step 2...")
    
    # Step 2: Calculate impacts
    analyzer = tutorial_step_2_calculate_basic_impact(events_df, prices_df)
    input("\nâ–¶ Press Enter to continue to Step 3...")
    
    # Step 3: Test significance
    result = tutorial_step_3_test_statistical_significance(analyzer, events_df)
    input("\nâ–¶ Press Enter to continue to Step 4...")
    
    # Step 4: Find correlations
    indirect_correlations = tutorial_step_4_discover_hidden_correlations(analyzer)
    input("\nâ–¶ Press Enter to continue to Step 5...")
    
    # Step 5: Risk analysis
    ticker = events_df['ticker'].iloc[0]
    event_type = events_df['event_type'].iloc[0]
    risk = tutorial_step_5_calculate_risk_metrics(analyzer, ticker, event_type)
    input("\nâ–¶ Press Enter to continue to Step 6...")
    
    # Step 6: Predict new event
    predictions = tutorial_step_6_predict_new_event(analyzer)
    input("\nâ–¶ Press Enter to continue to Step 7...")
    
    # Step 7: Interpretation guide
    tutorial_step_7_interpret_results()
    
    print("\n" + "="*70)
    print("ğŸ‰ TUTORIAL COMPLETE!")
    print("="*70)
    print("\nYou now understand:")
    print("âœ… How to load and validate data")
    print("âœ… How to calculate event impacts")
    print("âœ… How to test statistical significance")
    print("âœ… How to discover hidden correlations")
    print("âœ… How to calculate risk metrics")
    print("âœ… How to predict new events")
    print("âœ… How to interpret and apply results")
    
    print("\nğŸš€ Next Steps:")
    print("1. Get real historical data for your watchlist")
    print("2. Run this analysis on your data")
    print("3. Document your findings")
    print("4. Integrate into your dashboard")
    print("5. Start paper trading with predictions")
    
    print("\nğŸ’¼ Resume Talking Points:")
    print("â€¢ 'Built event study framework to analyze market reactions'")
    print("â€¢ 'Discovered statistically significant cross-asset correlations'")
    print("â€¢ 'Implemented VaR and risk-adjusted return calculations'")
    print("â€¢ 'Validated predictions using rigorous hypothesis testing'")
    print("\n")


if __name__ == "__main__":
    print("\nSelect mode:")
    print("1. Full interactive tutorial")
    print("2. Jump to specific step")
    print("3. Quick demonstration")
    
    choice = input("\nYour choice (1-3): ").strip()
    
    if choice == "1":
        full_tutorial()
    elif choice == "2":
        print("\nWhich step?")
        print("1 = Load Data")
        print("2 = Calculate Impacts")
        print("3 = Statistical Testing")
        print("4 = Find Correlations")
        print("5 = Risk Analysis")
        print("6 = Predict Events")
        print("7 = Interpretation Guide")
        
        step = input("\nStep number: ").strip()
        
        if step == "1":
            tutorial_step_1_load_data()
        elif step == "7":
            tutorial_step_7_interpret_results()
        # Add other steps as needed
    else:
        print("\nğŸ¬ Quick Demo Mode\n")
        events_df, prices_df = tutorial_step_1_load_data()
        analyzer = tutorial_step_2_calculate_basic_impact(events_df, prices_df)
        tutorial_step_4_discover_hidden_correlations(analyzer)
        print("\nDemo complete! Run full tutorial for detailed walkthrough.")
